# ====================================================================
#
# Copyright (C) 2011, Hewlett-Packard Development Company, L.P.
# All Rights Reserved.
#
# Open64 is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# Open64 is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
# MA  02110-1301, USA.
#
# ====================================================================
#
# This file contains a description of the possible results you can get from
# performing a test. The format is a series of 4-tuples, with each field in the
# 4-tuple separated by '@' character. This file is supposed to be easily
# script-readable, not human-readable.
#
# For a tuple <X,Y,P,Z>, "X" is the tag generated by TM internally within the
# cumulative messages directory (this is the suffix of the file that TM looks
# for). "Y" is the description attached to the failure that appears in the TM
# log file. "P" is a set of properties separated with blank spaces. "Z" is a
# more verbose description of the failure suitable for display on a web page.
#
SuccessExec@PASSES@@Test completed successfully.
#
DriverInternalError@DRIVER SCRIPT ERRORS@@This error indicates that a fatal internal error took place in one of the driver scripts executing the test. This is generally an indication that there is some sort of bug in the script.
#
CompareInternalError@COMPARE SCRIPT ERRORS@@An internal error took place in one of the compare scripts invoked to compare error or runtime output. This is generally an indication that there is some sort of bug in the script or in the testing harness.
#
FilterInternalError@FILTER SCRIPT ERRORS@@An internal error took place in one of the scripts used for output filtering. This is generally an indication that there is some sort of bug in the script or in the testing harness.
#
ScriptInternalError@MISC SCRIPT ERRORS@@An internal error took place in one of the scripts invoked as part of the test via a *_HOOKS variable. Typically an indication of a bug in the script or in the harness.
#
PreRunHookError@PRERUNHOOK ERRORS@@One of the scripts executed prior to running a unit (as part of PRE_RUN_HOOKS) returned a bad exit status value. This is typically an indication that the script could not properly set up execution of the unit. 
PostRunHookError@POSTRUNHOOK ERRORS@@One of the scripts executed prior to running a unit (as part of POST_RUN_HOOKS) returned a bad exit status value. This is typically an indication that the script could not properly set up execution of the unit. 
#
NoMasterOut@NO MASTER OUT FAILURES@@This error indicates that TM could not locate the master output file for the test (in cases where the test is runnable). 
#
NoMasterErr@NO MASTER ERR FAILURES@@This error indicates that TM could not locate the master compiler/linker error output file for the test.
#
CompileErr@COMPILATION FAILURES@CT_TRIAGEABLE@Some portion of the compile failed for this test. Depending on the test bucket, compilation failures may also include failures to link.
#
CompileBadPass@COMPILATION PASS FAILURES@CT_TRIAGEABLE@This test result is used by the regression test driver. It is used to flag tests where the compile passed even though we expected it to fail. 
#
LinkErr@LINKING FAILURES@CT_TRIAGEABLE@The test compiled cleanly but failed to link.
#
LinkBadPass@LINK PASS FAILURES@CT_TRIAGEABLE@This test result is used by the regression test driver. It is used to flag tests where the link passed even though we expected it to fail. 
#
AssembleErr@ASSEMBLER FAILURES@@An error took place when running the assembler while performing this test.
#
ExecErr@EXECUTION FAILURES@RT_TRIAGEABLE@For runnable tests, an execution failure took place. For regression tests, this indicates that the test failed to execute cleanly; for applications this generally means that running the test executable did not produce the expected output.
#
ExecBadPass@EXECUTION PASS FAILURES@RT_TRIAGEABLE@This test result is used by the regression test driver. It is used to flag tests where the execution passed even though we expected it to fail. 
#
DiffCcLdMsg@COMPILER or LINKER DIFFERENCE FAILURES@CT_TRIAGEABLE@The output generated by the compiler and linker during compilation of this test did not match the expected master compiler/linker error output file.
#
DiffAsLdMsg@ASSEMBLER or LINKER DIFFERENCE FAILURES@@The output generated by the assembler and linker during assembling of this test did not match the expected master assembler/linker error output file.
#
DiffAsMsg@ASSEMBLER DIFFERENCE FAILURES@@The output generated by the assembler during assembling of this test did not match the expected master assembler error output file.
#
DiffPgmOut@OUTPUT DIFFERENCE FAILURES@RT_TRIAGEABLE@For runnable tests, this indicates that the output produced by running the test executable did not match the expected (master) output file.
#
LongCompilation@LONG COMPILATION FAILURES@@A timeout occurred while waiting for completion of the compile portion of this test. 
#
LongLinking@LONG LINKING FAILURES@@A timeout occurred while waiting for completion of the link portion of this test. 
#
LongExec@LONG EXECUTION FAILURES@@A timeout occurred while waiting for the run of the test executable to complete.
#
LongCompare@TIMEOUT COMPARE FAILURES@@A timeout occurred while waiting for the compare script to complete. 
#
LongIterationHook@LONG ITERATION HOOK SCRIPT FAILURES@@A timeout occurred while waiting for a pre- or post-iteration hook script to complete. 
#
LongHook@LONG HOOK SCRIPT FAILURES@@A timeout occurred while waiting for a hook script (RUN_TESTS_HOOKS, etc) to complete. 
#
DiffCycDecMsg@CYCLE COUNT DECREASE FAILURES@RT_TRIAGEABLE@One or more of the static cycle counts for the test showed a decrease. 
#
DiffCycIncMsg@CYCLE COUNT INCREASE FAILURES@RT_TRIAGEABLE@One or more of the static cycle counts for the test showed an increase.
#
EmptyCycleMaster@EMPTY CYCLE COUNT MASTER@@The master *.err file for a cycle count test contains no procedures. This typically indicates a process problem with the test.
#
ScriptTestFailure@SCRIPT TEST FAILURES@@A script-based test failed. Depending on the script, this failure could be during compilation, linking, running, or output comparison.
#
LongScriptTest@LONG SCRIPT TESTS@@A script-based test exceeded its allotted time limit. 
#
DebugDriverRun@DRIVER RUNS STUBBED OUT FOR DEBUGGING PURPOSES@@Meta-driver stubbed out driver run for debugging purposes (script to debug driver written to unit work directory). 
#
UnknownUnitOrGroup@INACCESSIBLE OR UNKNOWN GROUPS/UNITS@@The test harness could not locate one or more units or groups mentioned in either the SELECTIONS setting or in the tmconfig file for some group listed in SELECTIONS.
#
GdbDiffPgmOut@GDB OUTPUT DIFFERENCE FAILURES@@For runnable tests, this indicates that the GDB output output produced by running the test executable under GDB did not match the expected (master) output file. It typically points to a problem with debug info generation.
#
Missing@MISSING TEST FAILURES@@This result type indicates that the test harness was supposed to execute a particular test, but the test was lost, presumably due to a problem with a test machine somewhere (ex: job launched to a machine that was rebooted during test execution).
#
PfyDiffMsg@PURIFY MESSAGE DIFFERENCE FAILURES@@Purify reported a different set of memory usage messages than expected (according to the master).
#
PfyDiffSum@PURIFY SUMMARY DIFFERENCE FAILURES@@Purify reported a significantly different set of summary statistics (compared to the master).
#
Cancelled@CANCELLED TESTS@@This result type indicates that the test in question was cancelled via a dtm_cancel command. This test is treated as a failure only in that it is not a 'pass'-- the test never actually ran in this case.
#
DwdMsg@DWD MESSAGE FAILURES@@dwd output was not as expected.
#
DwdFail@DWD RUN FAILURES@@dwd failed or returned bad exit status when run on the target executable.
#
CopyFailNoDisk@INSUFFICIENT DISK SPACE FAILURES@@This test indicates that CTI was unable to copy messages and/or debris for a unit back to the unit work directory, due to "low disk space" condition (ex: target file system is full).
#
CopyFailUnknown@RESULT COPY FAILURES@@This test indicates that CTI was unable to copy messages and/or debris for a unit back to the unit work directory. This may be due to insufficient permissions, problems with the result directory, a transient low-disk-space condition, or some other unspecified problem.
#
CadviseFail@CADVISE FAILURE@@The 'cadvise' executable returned a bad exit status when run on the application. 
#
CadviseOutputDiff@CADVISE OUTPUT DIFFERENCE FAILURE@@Output from 'cadvise' for the test case is different from the expected master.                     
#
CadviseNoMasterOutput@CADVISE NO MASTER FAILURE@@The cadvise master output file for the application is missing.
#
DocDiffFail@DOC DIFFERENCE FAILURE@@DOC testing failure. Indicates that addition of "-g" resulted in difference code for opt level +O2 and above.
#
LimitInternalError@LIMIT SCRIPT ERROR@@Time limit script encountered an internal error (could not locate correct version of Perl, or some other system error that prevented it from functioning properly).
#
PreprocPathDiffFail@PREPROCESSING PATH DIFFERENCE FAILURE@@Processing path difference failure. This failure indicates that for the specified test, the compiler is generating different code for the source file if it is first run through the preprocessor (-E.i) and the compiled. 
#
